{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model\n",
    "\n",
    "* Preprocessing of training and problem test data is done \n",
    "* Final training and problem test data is created\n",
    "* In previously defined training sets, every training data had some new features, some of the features found to be important, hence these  features are added in new training and problem test which result in final data \n",
    "* This time training data is split in 3 part train set, dev set and test set(this test set is different from the problem test set, this test set is part of training data itself use for the final test of the model)\n",
    "* Gradient boosting classifier is used, the model is trained on train set and hyperparameter tuning is done with the help of dev set\n",
    "* After fine-tuning of hyperparameter of the model it is tested over test set before applying on problem test data\n",
    "* After satisfaction predictions are done over the problem test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python virsion   : 3.7.1 (default, Dec 10 2018, 22:54:23) [MSC v.1915 64 bit (AMD64)]\n",
      "pandas virsion   : 0.23.4\n",
      "sklearn virsion  : 0.20.1\n",
      "numpy virsion    : 0.23.4\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('python virsion   :',sys.version)\n",
    "print('pandas virsion   :',pd.__version__)\n",
    "print('sklearn virsion  :',sklearn.__version__)\n",
    "print('numpy virsion    :',pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing train and problem test set\n",
    "train_data= pd.read_csv('train.csv')\n",
    "test_data= pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing of both data set, same as done before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " #deleting 'employee_id' and 'region' column\n",
    "train_data.drop(['employee_id','region'],axis=1,inplace=True)\n",
    "test_data.drop(['employee_id','region'],axis=1,inplace=True)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing values\n",
    "train_data.education.fillna('missing',inplace=True)\n",
    "for i in range(train_data.shape[0]):\n",
    "    if train_data['education'][i]=='missing':\n",
    "        if train_data['age'][i]<=25:\n",
    "            train_data['education'][i]='Below Secondary'\n",
    "        if train_data['age'][i]>25 and train_data['age'][i]<=32:\n",
    "            train_data['education'][i]=\"Bachelor's\"\n",
    "        if train_data['age'][i]>32:\n",
    "            train_data['education'][i]=\"Master's & above\"\n",
    "            \n",
    "\n",
    "test_data.education.fillna('missing',inplace=True)\n",
    "for i in range(test_data.shape[0]):\n",
    "    if test_data['education'][i]=='missing':\n",
    "        if test_data['age'][i]<=25:\n",
    "            test_data['education'][i]='Below Secondary'\n",
    "        if test_data['age'][i]>25 and test_data['age'][i]<=32:\n",
    "            test_data['education'][i]=\"Bachelor's\"\n",
    "        if test_data['age'][i]>32:\n",
    "            test_data['education'][i]=\"Master's & above\"\n",
    "\n",
    "train_data.previous_year_rating.fillna(train_data.previous_year_rating.mode()[0],inplace=True)\n",
    "test_data.previous_year_rating.fillna(train_data.previous_year_rating.mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating final train and test set, adding some importan features\n",
    "final_train= train_data.copy()\n",
    "final_test= test_data.copy()\n",
    "\n",
    "final_train['service_ratio']= final_train['length_of_service']/final_train['age']\n",
    "final_test['service_ratio']= final_test['length_of_service']/final_test['age']\n",
    "\n",
    "final_train['addtion_feature']= train_data['previous_year_rating']+train_data['KPIs_met >80%']+train_data['avg_training_score']+train_data['awards_won?']\n",
    "final_test['addtion_feature']= test_data['previous_year_rating']+test_data['KPIs_met >80%']+test_data['avg_training_score']+test_data['awards_won?']\n",
    "\n",
    "final_train['total_training_score'] = train_data['no_of_trainings']*train_data['avg_training_score']\n",
    "final_test['total_training_score'] = test_data['no_of_trainings']*test_data['avg_training_score']\n",
    "\n",
    "final_train['education'] = train_data['education'].map({'Below Secondary':0,\"Bachelor's\":1,\"Master's & above\":2}).astype(np.int)\n",
    "final_test['education'] = test_data['education'].map({'Below Secondary':0,\"Bachelor's\":1,\"Master's & above\":2}).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling both data\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "def scaleColumns(train,test, cols_to_scale):\n",
    "    for col in cols_to_scale:\n",
    "        train[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(train[col])),columns=[col])\n",
    "        test[col] = pd.DataFrame(scaler.transform(pd.DataFrame(test[col])),columns=[col])\n",
    "    return train, test\n",
    "\n",
    "\n",
    "fina_train,final_test = scaleColumns(final_train,final_test, ['no_of_trainings',\n",
    "                                                              'age','previous_year_rating',\n",
    "                                                              'length_of_service',\n",
    "                                                              'avg_training_score',\n",
    "                                                              'service_ratio',\n",
    "                                                              'addtion_feature',\n",
    "                                                              'total_training_score',\n",
    "                                                              'total_training_score',\n",
    "                                                              'education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variable\n",
    "final_train = pd.get_dummies(final_train, drop_first=True)\n",
    "final_test = pd.get_dummies(final_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding one more feature which is 1 dimensional represention of data with the help of PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1)\n",
    "d1_train = pca.fit_transform(final_train.drop(['is_promoted'],axis=1))\n",
    "d1_test = pca.transform(final_test)\n",
    "\n",
    "final_train['summay']= d1_train\n",
    "final_test['summay']= d1_test\n",
    "\n",
    "train_data, test =train_test_split(final_train, test_size=0.3, random_state=42)\n",
    "train, dev =train_test_split(train_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating independent variable i.e. X and dependent variable i.e. y\n",
    "X_train = train.drop(['is_promoted'],axis=1)\n",
    "y_train = train['is_promoted']\n",
    "\n",
    "X_dev = dev.drop(['is_promoted'],axis=1)\n",
    "y_dev = dev['is_promoted']\n",
    "\n",
    "X_test = test.drop(['is_promoted'],axis=1)\n",
    "y_test = test['is_promoted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model\n",
    "model=GradientBoostingClassifier(max_depth=3,min_samples_split=5,\n",
    "                                  min_samples_leaf=7,\n",
    "                                  min_weight_fraction_leaf=.01,n_estimators=1000, random_state=42,max_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=20, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=7, min_samples_split=5,\n",
       "              min_weight_fraction_leaf=0.01, n_estimators=1000,\n",
       "              n_iter_no_change=None, presort='auto', random_state=42,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precting probability of dev set\n",
    "y_prob_dev = model.predict_proba(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum f1 score : 0.5376623376623376\n",
      "threshold         : 0.36\n"
     ]
    }
   ],
   "source": [
    "#applying 'for loop' for getting max f1 score and respective threshold \n",
    "f1score = []\n",
    "max_f1 =0\n",
    "x =[]\n",
    "for i in range(100):\n",
    "    y_hat_prob_dev = y_prob_dev[:,1]> i/100\n",
    "    f1 = f1_score(y_dev, y_hat_prob_dev)\n",
    "    f1score.append(f1)\n",
    "    x.append(i)\n",
    "    if f1 > max_f1:\n",
    "        max_f1 = f1\n",
    "        threshold= i/100\n",
    "print('maximum f1 score :',max_f1)\n",
    "print('threshold         :',threshold)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2d15b135dd8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score vs threshold probability curve\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "sns.scatterplot(x,f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After fine tuning of model testing of test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5091267883571781"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob_test = model.predict_proba(X_test)\n",
    "y_hat_prob_test = y_prob_test[:,1]> threshold\n",
    "f1_score(y_test, y_hat_prob_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After satisfactory performance, model predicaton made on problem test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X= final_test\n",
    "test_y_prob= model.predict_proba(test_X)\n",
    "test_y_hat_prob = test_y_prob[:,1]>threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving predicton of problem test file for submission\n",
    "test_y=pd.DataFrame(data=test_y_hat_prob,columns=[\"is_promoted\"]).astype('int64')\n",
    "prediction = pd.concat([pd.read_csv('test.csv').employee_id,test_y],axis=1)\n",
    "prediction.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
